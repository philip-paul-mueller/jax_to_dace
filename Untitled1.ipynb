{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "896262d4-df1c-4afd-a65f-42c3d909a2a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def f(x):\n",
    "  y = sin(x) * 2.\n",
    "  z = - y + x\n",
    "  return z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4fc0aafc-dbc4-48fe-8f18-d7f562891a26",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import NamedTuple\n",
    "\n",
    "class Primitive(NamedTuple):\n",
    "  name: str\n",
    "\n",
    "add_p = Primitive('add')\n",
    "mul_p = Primitive('mul')\n",
    "neg_p = Primitive(\"neg\")\n",
    "sin_p = Primitive(\"sin\")\n",
    "cos_p = Primitive(\"cos\")\n",
    "reduce_sum_p = Primitive(\"reduce_sum\")\n",
    "greater_p = Primitive(\"greater\")\n",
    "less_p = Primitive(\"less\")\n",
    "transpose_p = Primitive(\"transpose\")\n",
    "broadcast_p = Primitive(\"broadcast\")\n",
    "\n",
    "def add(x, y): return bind1(add_p, x, y)\n",
    "def mul(x, y): return bind1(mul_p, x, y)\n",
    "def neg(x): return bind1(neg_p, x)\n",
    "def sin(x): return bind1(sin_p, x)\n",
    "def cos(x): return bind1(cos_p, x)\n",
    "def greater(x, y): return bind1(greater_p, x, y)\n",
    "def less(x, y): return bind1(less_p, x, y)\n",
    "def transpose(x, perm): return bind1(transpose_p, x, perm=perm)\n",
    "def broadcast(x, shape, axes): return bind1(broadcast_p, x, shape=shape, axes=axes)\n",
    "def reduce_sum(x, axis=None):\n",
    "  if axis is None:\n",
    "    axis = tuple(range(np.ndim(x)))\n",
    "  if type(axis) is int:\n",
    "    axis = (axis,)\n",
    "  return bind1(reduce_sum_p, x, axis=axis)\n",
    "\n",
    "def bind1(prim, *args, **params):\n",
    "  out, = bind(prim, *args, **params)\n",
    "  return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8ec33ac2-0885-4b99-b103-2f7c4c7d9ba9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections.abc import Sequence\n",
    "from contextlib import contextmanager\n",
    "from typing import Optional, Any\n",
    "\n",
    "class MainTrace(NamedTuple):\n",
    "    \"\"\"This is more like a 'parametrizable `Trace` factory' that will generate a trace of type `trace_type`.\n",
    "    Instance of this (`MainTrace`) are builded by `new_main` and put on the trace.\n",
    "    The factory function should be located in `find_top_trace()`.\n",
    "\n",
    "    \"\"\"\n",
    "    level: int\n",
    "    trace_type: type['Trace']\n",
    "    global_data: Optional[Any]\n",
    "\n",
    "\"\"\"This is the stack of all active `MainTrace`s\n",
    "They are filled via the context manager `new_main()` or `new_dynamic()`.\n",
    "The stack is usually inspected by `find_top_trace()`\n",
    "\"\"\"\n",
    "trace_stack: list[MainTrace] = []\n",
    "\n",
    "\"\"\"This is an instance of a `MainTrace` and it is maintained by `new_dynamic()`.\n",
    "Essentially it allows to inject a `MainTrace` into the resolution of `find_top_trace()`.\n",
    "By default that function will select the most recent `MainTrace` that created the involved variables.\n",
    "However, this variables allows to select a different one, that was not involved in the creation of any of the `Tracer`s passed to `find_top_trace()`.\n",
    "\"\"\"\n",
    "dynamic_trace: Optional[MainTrace] = None  # to be employed in Part 3\n",
    "\n",
    "@contextmanager\n",
    "def new_main(trace_type: type['Trace'], global_data=None):\n",
    "    level = len(trace_stack)\n",
    "    main = MainTrace(level, trace_type, global_data)\n",
    "    trace_stack.append(main)\n",
    "    \n",
    "    try:\n",
    "        yield main\n",
    "    finally:\n",
    "        trace_stack.pop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ad5e2c1c-b339-4de5-9fd3-3810c47b93ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Trace:\n",
    "    \"\"\"According to rthe guid a better word for `Trace` would be 'Interpreter'.    \n",
    "    \"\"\"\n",
    "    main: MainTrace\n",
    "    \n",
    "    def __init__(self, main: MainTrace) -> None:\n",
    "        self.main = main\n",
    "    \n",
    "    def pure(self, val):\n",
    "        \"\"\"Wrap `val` into a `Tracer` instance.\n",
    "        \n",
    "        This function constructs an instance of the associated `Tracer` class of `self`.\n",
    "        The function is inetnded for the case when `val` is not a tracer yet.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "        \n",
    "    def lift(self, val):\n",
    "        \"\"\"Wrap `val` into an instance of the associated `Tracer` type.\n",
    "\n",
    "        While this function has basically the same implementation as `pure()` is has a different intend.\n",
    "        This function operates on `val` instances that are already `Tracer`, but they are associated `MainTrace` that have a lover level (Older).\n",
    "\n",
    "        To undo this lift the `Tracer` provides the `full_lower()` member function.\n",
    "\n",
    "        It is unlikely that you will use this function directly, or at all.\n",
    "        However, it is used by `full_raise()` to promote all `Tracer`s that are passed to it to a common level. \n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    \n",
    "    def process_primitive(self, primitive, tracers, params):\n",
    "        \"\"\"Applies the rules that are associated to a concrete `Trace`.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "0bf13b9b-ea8a-4784-8ed2-2bed2065a79a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "class Tracer:\n",
    "    \"\"\"This is the base of all variables (what is the connection to `ShapedArray`) that are traced through the function.\n",
    "    It contains reference to the trace that generated it `self._trace`.\n",
    "    Further, it contains the property `aval` that it wraps at least that is what I think, however its connection to shaped array is unclear to me.\n",
    "    Furthermore, it seams that you should access `self.aval` only through the `get_aval()` function.\n",
    "\n",
    "    Instances of a `Tracer` are constructed by calling either `pure()` or `lift()` on a concrete `Trace` instance and they are called by `full_raise()`\n",
    "\n",
    "    More about the meaning of `self.aval`\n",
    "    \n",
    "    \"\"\"\n",
    "    _trace: Trace = None    # Deriving classes will create an instance variable of this member.\n",
    "    \n",
    "    __array_priority__ = 1000\n",
    "\n",
    "    def __init__(self, trace: Trace):\n",
    "        self._trace = trace\n",
    "    #\n",
    "    \n",
    "    @property\n",
    "    def aval(self):\n",
    "        \"\"\"This is to access the variable they represents.\n",
    "\n",
    "        You should not call it directly instead you should use the global `get_aval()` free function.\n",
    "\n",
    "        Note:\n",
    "            Deriving classes have to override this function.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError\n",
    "    #\n",
    "    \n",
    "    def full_lower(self):\n",
    "        \"\"\"In essence this function can undo a `lift()` operation.\n",
    "\n",
    "        To put it differently, if a tracer was lifted, i.e. wraps another tracer, this function returns the underling `Tracer` instance.\n",
    "        However, you should not call it directly, instead use the `full_lower()` global function.\n",
    "        \"\"\"\n",
    "        return self  # default implementation\n",
    "    #\n",
    "\n",
    "    \n",
    "    def __neg__(self): return self.aval._neg(self)\n",
    "    def __add__(self, other): return self.aval._add(self, other)\n",
    "    def __radd__(self, other): return self.aval._radd(self, other)\n",
    "    def __mul__(self, other): return self.aval._mul(self, other)\n",
    "    def __rmul__(self, other): return self.aval._rmul(self, other)\n",
    "    def __gt__(self, other): return self.aval._gt(self, other)\n",
    "    def __lt__(self, other): return self.aval._lt(self, other)\n",
    "    def __bool__(self): return self.aval._bool(self)\n",
    "    def __nonzero__(self): return self.aval._nonzero(self)\n",
    "    \n",
    "    def __getattr__(self, name):\n",
    "        try:\n",
    "            return getattr(self.aval, name)\n",
    "        except AttributeError:\n",
    "            raise AttributeError(f\"{self.__class__.__name__} has no attribute {name}\")\n",
    "    #\n",
    "# end class(Trace):\n",
    "    \n",
    "def swap(f): return lambda x, y: f(y, x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb9f3d12-ac23-4367-9033-99de1c4c32b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ShapedArray:\n",
    "  array_abstraction_level = 1\n",
    "  shape: tuple[int, ...]\n",
    "  dtype: np.dtype\n",
    "\n",
    "  def __init__(self, shape, dtype):\n",
    "    self.shape = shape\n",
    "    self.dtype = dtype\n",
    "\n",
    "  @property\n",
    "  def ndim(self):\n",
    "    return len(self.shape)\n",
    "\n",
    "  _neg = staticmethod(neg)\n",
    "  _add = staticmethod(add)\n",
    "  _radd = staticmethod(swap(add))\n",
    "  _mul = staticmethod(mul)\n",
    "  _rmul = staticmethod(swap(mul))\n",
    "  _gt = staticmethod(greater)\n",
    "  _lt = staticmethod(less)\n",
    "\n",
    "  @staticmethod\n",
    "  def _bool(tracer):\n",
    "    raise Exception(\"ShapedArray can't be unambiguously converted to bool\")\n",
    "\n",
    "  @staticmethod\n",
    "  def _nonzero(tracer):\n",
    "    raise Exception(\"ShapedArray can't be unambiguously converted to bool\")\n",
    "\n",
    "  def str_short(self):\n",
    "    return f'{self.dtype.name}[{\",\".join(str(d) for d in self.shape)}]'\n",
    "\n",
    "  def __hash__(self):\n",
    "    return hash((self.shape, self.dtype))\n",
    "\n",
    "  def __eq__(self, other):\n",
    "    return (type(self) is type(other) and\n",
    "            self.shape == other.shape and self.dtype == other.dtype)\n",
    "\n",
    "  def __repr__(self):\n",
    "    return f\"ShapedArray(shape={self.shape}, dtype={self.dtype})\"\n",
    "\n",
    "class ConcreteArray(ShapedArray):\n",
    "  array_abstraction_level = 2\n",
    "  val: np.ndarray\n",
    "\n",
    "  def __init__(self, val):\n",
    "    self.val = val\n",
    "    self.shape = val.shape\n",
    "    self.dtype = val.dtype\n",
    "\n",
    "  @staticmethod\n",
    "  def _bool(tracer):\n",
    "    return bool(tracer.aval.val)\n",
    "\n",
    "  @staticmethod\n",
    "  def _nonzero(tracer):\n",
    "    return bool(tracer.aval.val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "6eb86354-dc47-4d19-b44b-17d7de402da1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"These are all types that we consider as valid types.\n",
    "\"\"\"\n",
    "jax_types = {bool, int, float,\n",
    "             np.bool_, np.int32, np.int64, np.float32, np.float64, np.ndarray}\n",
    "\n",
    "def get_aval(x):\n",
    "    \"\"\"This function is a save way of accessing the `.aval` property on _abny_ object.\n",
    "\n",
    "    If `x` is a `Tracer` it will just return the property.\n",
    "    In case it is a type that is inside `jax_types` it will construct a concrete array out of `x` and return that.\n",
    "    In all other cases it will error.\n",
    "\n",
    "    In essence this function is needed because `EvalTrace` does not have an associated `Tracer` class.\n",
    "    \"\"\"\n",
    "    if isinstance(x, Tracer):\n",
    "        return x.aval\n",
    "    elif type(x) in jax_types:\n",
    "        return ConcreteArray(np.asarray(x))\n",
    "    elif isinstance(x, ConcreteArray):    # The original code dod not have it, but according to my understanding it is needed\n",
    "        return x\n",
    "    #\n",
    "    raise TypeError(x)\n",
    "#\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459bf05e-8a93-4466-a385-37c81f4850f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1aa85d46-c341-4c2c-a405-1e145651310e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import operator as op\n",
    "\n",
    "def find_top_trace(xs) -> Trace:\n",
    "    \"\"\"Dispate its name this function does not find the top trace (okay in a way it does but it does not returns it).\n",
    "\n",
    "    Instead it does the following:\n",
    "    - It will fillter out all variables that are _not_ derived from `Tracer`, thus we will only process on them.\n",
    "    - By inspecting their `_trace.main` (second order member) it will figuring out to which `MainTrace` reach tracer is associated.\n",
    "    - It will then look for the `MainTrace` in the higest stack position, i.e. the last that was made active.\n",
    "        Thus, latest `MainTrace` is selected that was involved in the creation of any of teh passed variables, and not the `MainTrace` that was most recently created. \n",
    "    - However, in case a `dynamic_trace` is active and it is newer than the one found, it will be used.\n",
    "    - Then the function will use the `trace_type` member of the found `MainTrace` instance to create a new `Trace` instance.  \n",
    "    \"\"\"\n",
    "    top_main = max((x._trace.main for x in xs if isinstance(x, Tracer)),\n",
    "                    default=trace_stack[0], key=op.attrgetter('level'))\n",
    "    if dynamic_trace and dynamic_trace.level > top_main.level:\n",
    "        top_main = dynamic_trace\n",
    "    return top_main.trace_type(top_main)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c9fa1da2-adb7-4a7f-adc7-daaf3b44e04b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _full_lower(val: Any):\n",
    "    \"\"\"Save way to call `full_lower()` on any object.\n",
    "\n",
    "    If `val` is an instance of a `Tracer` the function calls `val.full_lower()`.\n",
    "    In all other cases the function just returns `val`.\n",
    "    \"\"\"\n",
    "    if isinstance(val, Tracer):\n",
    "        return val.full_lower()\n",
    "    else:\n",
    "        return val\n",
    "    #\n",
    "\n",
    "def full_lower(*vals):\n",
    "    \"\"\"Save way to call `full_lower()` on any objects.\n",
    "\n",
    "    Same as `_full_lower()` accepts vardicac numbers of arguments.\n",
    "    \"\"\"\n",
    "    return tuple(_full_lower(val)  for val in vals)\n",
    "#\n",
    "\n",
    "\n",
    "def full_raise(common_trace: Trace,  val: Any):\n",
    "    \"\"\"Uses `trace` to construct the associated `Tracer` from `val`.\n",
    "\n",
    "    If `val` is not a `Tracer` the function will call `trace.pure()` to construct one.\n",
    "    If `val` is already a `Tracer` it will use `trace.lift()` to lift it to the desired level.\n",
    "    In addition the function will perform some checks if the transformation is allowed.\n",
    "    For example the function will never lower the tracer.\n",
    "    \"\"\"\n",
    "    if not isinstance(val, Tracer):\n",
    "        assert type(val) in jax_types, f\"Got type '{type(val)}' whioch is not inside {jax_types}\"\n",
    "        return common_trace.pure(val)\n",
    "    level = common_trace.main.level\n",
    "    if val._trace.main is common_trace.main:\n",
    "        return val\n",
    "    elif val._trace.main.level < level:\n",
    "        return common_trace.lift(val)\n",
    "    elif val._trace.main.level > level:\n",
    "        raise Exception(f\"Can't lift level {val._trace.main.level} to {level}.\")\n",
    "    else:  # val._trace.level == level\n",
    "        raise Exception(f\"Different traces at same level: {val._trace}, {trace}.\")\n",
    "#\n",
    "\n",
    "\n",
    "\n",
    "def full_raise_all(*vals, ret_top_tracer=False, common_trace=None) -> Tracer:\n",
    "    \"\"\"Transform all arguments into `Tracer`.\n",
    "\n",
    "    The function is similar to `full_raise()` except that it operates on any number of arguments.\n",
    "    Further the functioen will determine the common `Trace` instance on its own by calling `find_top_trace()`.\n",
    "    But it is possible to supy a different trace.\n",
    "    \"\"\"\n",
    "    if(common_trace is not None):\n",
    "        assert isinstance(common_trace, Trace)\n",
    "        highest_common_trace: Trace = common_trace\n",
    "    else:\n",
    "        highest_common_trace: Trace = find_top_trace(vals)\n",
    "    raised_tracers = []\n",
    "    for val in vals:\n",
    "        raised_tracers.append(_full_raise(highest_common_trace, val))\n",
    "    return (raised_tracers, highest_common_trace) if ret_top_tracer else raised_tracers\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70ca002-ccfe-4b96-aaf5-632edd9b27f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "fefa3ed0-6301-4fd3-ac2c-e203f54575a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bind(prim, *args, **params):\n",
    "    \"\"\"This function applies \n",
    "    \"\"\"\n",
    "    common_trace = find_top_trace(args)\n",
    "    tracers      = full_raise_all(*args, common_trace=common_trace)\n",
    "    outs         = common_trace.process_primitive(prim, tracers, params)\n",
    "    lower_outs   = full_lower(*outs)\n",
    "    return lower_outs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c119210b-9241-4175-9c93-d8deb7f388a7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "747e655a-3a5c-4afa-9c52-d21dc62a7747",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "807ac931-3ba1-4da3-a4ea-aec7eabef5a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class EvalTrace(Trace):\n",
    "    \"\"\"This is the Evaluation Trace.\n",
    "\n",
    "    It is special in the sense that there is no associated `Tracer` to this class since it is just about evaluation.\n",
    "    So there is no need to \"collect the operations\".\n",
    "    Furthermore, there will always be an instance of a `MainTrace` with `EvalTrace` as `trace_type` at the bottom of teh `trace_stack`.\n",
    "\n",
    "    The rules for processing the primitives are inside the global `dict` `impl_rules`.\n",
    "    \"\"\"\n",
    "\n",
    "    def pure(self, x):\n",
    "        \"\"\"Since there is no associated `Tracer` class the `pure()` function always returns its argument.\n",
    "        The same is true for the `lift()` function.\n",
    "        \"\"\"\n",
    "        return x\n",
    "        \n",
    "    def lift(self, x):\n",
    "        \"\"\"See `self.pure()`.\n",
    "        \"\"\"\n",
    "        return x\n",
    "    #\n",
    "    \n",
    "    def process_primitive(self, primitive, tracers, params):\n",
    "        return impl_rules[primitive](*tracers, **params)\n",
    "# end class(EvalTrace):\n",
    "\n",
    "\n",
    "trace_stack.append(MainTrace(0, EvalTrace, None))  # special bottom of the stack\n",
    "\n",
    "# NB: in JAX, instead of a dict we attach impl rules to the Primitive instance\n",
    "impl_rules = {}\n",
    "\n",
    "impl_rules[mul_p] = lambda x, y: [np.multiply(x, y)]\n",
    "impl_rules[neg_p] = lambda x: [np.negative(x)]\n",
    "impl_rules[cos_p] = lambda x: [np.cos(x)]\n",
    "impl_rules[reduce_sum_p] = lambda x, *, axis: [np.sum(x, axis)]\n",
    "impl_rules[greater_p] = lambda x, y: [np.greater(x, y)]\n",
    "impl_rules[less_p] = lambda x, y: [np.less(x, y)]\n",
    "impl_rules[transpose_p] = lambda x, *, perm: [np.transpose(x, perm)]\n",
    "\n",
    "def add_impl(x, y):\n",
    "    #raise ValueError(\"hjhjhj\")\n",
    "    return [np.add(x, y)]\n",
    "impl_rules[add_p] = add_impl\n",
    "\n",
    "def sin_impl(x):\n",
    "    #raise ValueError(\"hjhjhj\")\n",
    "    return [np.sin(x)]\n",
    "impl_rules[sin_p] = sin_impl\n",
    "\n",
    "\n",
    "def broadcast_impl(x, *, shape, axes):\n",
    "    for axis in sorted(axes):\n",
    "    x = np.expand_dims(x, axis)\n",
    "    return [np.broadcast_to(x, shape)]\n",
    "impl_rules[broadcast_p] = broadcast_impl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c45e066-11bd-4286-a08a-97edfe472c51",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "56d1d910-1df5-4fde-be2a-2d6caf8980c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import builtins\n",
    "\n",
    "def zeros_like(val):\n",
    "  aval = get_aval(val)\n",
    "  return np.zeros(aval.shape, aval.dtype)\n",
    "\n",
    "def unzip2(pairs):\n",
    "  lst1, lst2 = [], []\n",
    "  for x1, x2 in pairs:\n",
    "    lst1.append(x1)\n",
    "    lst2.append(x2)\n",
    "  return lst1, lst2\n",
    "\n",
    "def map(f, *xs):\n",
    "  return list(builtins.map(f, *xs))\n",
    "\n",
    "def zip(*args):\n",
    "  fst, *rest = args = map(list, args)\n",
    "  n = len(fst)\n",
    "  for arg in rest:\n",
    "    assert len(arg) == n\n",
    "  return list(builtins.zip(*args))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "def325a6-b510-42b5-be0d-b03d697d9077",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JVPTracer(Tracer):\n",
    "    def __init__(self, trace, primal, tangent):\n",
    "        self._trace = trace\n",
    "        self.primal = primal\n",
    "        self.tangent = tangent\n",
    "    \n",
    "    @property\n",
    "    def aval(self):\n",
    "        return get_aval(self.primal)\n",
    "    \n",
    "    \n",
    "    \n",
    "    \n",
    "class JVPTrace(Trace):\n",
    "    pure = lift = lambda self, val: JVPTracer(self, val, zeros_like(val))\n",
    "    \n",
    "    def process_primitive(self, primitive, tracers, params):\n",
    "    primals_in, tangents_in = unzip2((t.primal, t.tangent) for t in tracers)\n",
    "    jvp_rule = jvp_rules[primitive]\n",
    "    primal_outs, tangent_outs = jvp_rule(primals_in, tangents_in, **params)\n",
    "    return [JVPTracer(self, x, t) for x, t in zip(primal_outs, tangent_outs)]\n",
    "    \n",
    "jvp_rules = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7efb84c7-ce6f-44b8-880b-ea808ce58d65",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_jvp(primals, tangents):\n",
    "  (x, y), (x_dot, y_dot) = primals, tangents\n",
    "  return [x + y], [x_dot + y_dot]\n",
    "jvp_rules[add_p] = add_jvp\n",
    "\n",
    "def mul_jvp(primals, tangents):\n",
    "  (x, y), (x_dot, y_dot) = primals, tangents\n",
    "  return [x * y], [x_dot * y + x * y_dot]\n",
    "jvp_rules[mul_p] = mul_jvp\n",
    "\n",
    "def sin_jvp(primals, tangents):\n",
    "  (x,), (x_dot,) = primals, tangents\n",
    "  return [sin(x)], [cos(x) * x_dot]\n",
    "jvp_rules[sin_p] = sin_jvp\n",
    "\n",
    "def cos_jvp(primals, tangents):\n",
    "  (x,), (x_dot,) = primals, tangents\n",
    "  return [cos(x)], [-sin(x) * x_dot]\n",
    "jvp_rules[cos_p] = cos_jvp\n",
    "\n",
    "def neg_jvp(primals, tangents):\n",
    "  (x,), (x_dot,) = primals, tangents\n",
    "  return [neg(x)], [neg(x_dot)]\n",
    "jvp_rules[neg_p] = neg_jvp\n",
    "\n",
    "def reduce_sum_jvp(primals, tangents, *, axis):\n",
    "  (x,), (x_dot,) = primals, tangents\n",
    "  return [reduce_sum(x, axis)], [reduce_sum(x_dot, axis)]\n",
    "jvp_rules[reduce_sum_p] = reduce_sum_jvp\n",
    "\n",
    "def greater_jvp(primals, tangents):\n",
    "  (x, y), _ = primals, tangents\n",
    "  out_primal = greater(x, y)\n",
    "  return [out_primal], [zeros_like(out_primal)]\n",
    "jvp_rules[greater_p] = greater_jvp\n",
    "\n",
    "def less_jvp(primals, tangents):\n",
    "  (x, y), _ = primals, tangents\n",
    "  out_primal = less(x, y)\n",
    "  return [out_primal], [zeros_like(out_primal)]\n",
    "jvp_rules[less_p] = less_jvp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c8678e5f-3c25-46d0-90ae-6de5a9e4a61c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jvp_v1(f, primals, tangents):\n",
    "    with new_main(JVPTrace) as main:\n",
    "        trace = JVPTrace(main)\n",
    "        tracers_in = [JVPTracer(trace, x, t) for x, t in zip(primals, tangents)]\n",
    "        out = f(*tracers_in)\n",
    "        tracer_out = full_raise(trace, out)\n",
    "        primal_out, tangent_out = tracer_out.primal, tracer_out.tangent\n",
    "        return primal_out, tangent_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "cce1fb1c-377c-41bf-94b5-b2a56be3d484",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.9899924966004454\n",
      "-0.9899924966004454\n"
     ]
    }
   ],
   "source": [
    "x = 3.0\n",
    "y, sin_deriv_at_3 = jvp_v1(sin, (x,), (1.0,))\n",
    "print(sin_deriv_at_3)\n",
    "print(cos(3.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "2494fc02-cecb-4d8a-aec6-40cf5bffa5eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.979984993200891\n",
      "2.979984993200891\n"
     ]
    }
   ],
   "source": [
    "x = 3.0\n",
    "yf, ydf = jvp_v1(f, (x,), (1.0,))\n",
    "print(ydf)\n",
    "print(1 - 2 * np.cos(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59e0b295-a8b8-4f25-84ce-3ee3f6d10f93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jvp(f, primals, tangents):\n",
    "  primals_flat, in_tree = tree_flatten(primals)\n",
    "  tangents_flat, in_tree2 = tree_flatten(tangents)\n",
    "  if in_tree != in_tree2: raise TypeError\n",
    "  f, out_tree = flatten_fun(f, in_tree)\n",
    "  primals_out_flat, tangents_out_flat = jvp_flat(f, primals_flat, tangents_flat)\n",
    "  primals_out = tree_unflatten(out_tree(), primals_out_flat)\n",
    "  tangents_out = tree_unflatten(out_tree(), tangents_out_flat)\n",
    "  return primals_out, tangents_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "febfbe31-4413-48ff-bef0-96093eb49666",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jvp_flat(f, primals, tangents):\n",
    "    with new_main(JVPTrace) as main:\n",
    "        trace = JVPTrace(main)\n",
    "        tracers_in = [JVPTracer(trace, x, t) for x, t in zip(primals, tangents)]\n",
    "        outs = f(*tracers_in)\n",
    "        tracers_out = [full_raise(trace, out) for out in outs]\n",
    "        primals_out, tangents_out = unzip2((t.primal, t.tangent) for t in tracers_out)\n",
    "        return primals_out, tangents_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "282b229f-bd67-430c-b5ec-0ca8e53925d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten_fun(f, in_tree):\n",
    "  store = Store()\n",
    "\n",
    "  def flat_fun(*args_flat):\n",
    "    pytree_args = tree_unflatten(in_tree, args_flat)\n",
    "    out = f(*pytree_args)\n",
    "    out_flat, out_tree = tree_flatten(out)\n",
    "    store.set_value(out_tree)\n",
    "    return out_flat\n",
    "\n",
    "  return flat_fun, store\n",
    "\n",
    "class Empty: pass\n",
    "empty = Empty()\n",
    "\n",
    "class Store:\n",
    "  val = empty\n",
    "\n",
    "  def set_value(self, val):\n",
    "    assert self.val is empty\n",
    "    self.val = val\n",
    "\n",
    "  def __call__(self):\n",
    "    return self.val\n",
    "\n",
    "\n",
    "from collections.abc import Hashable, Iterable, Iterator\n",
    "import itertools as it\n",
    "from typing import Callable\n",
    "\n",
    "class NodeType(NamedTuple):\n",
    "  name: str\n",
    "  to_iterable: Callable\n",
    "  from_iterable: Callable\n",
    "\n",
    "def register_pytree_node(ty: type, to_iter: Callable, from_iter: Callable\n",
    "                         ) -> None:\n",
    "  node_types[ty] = NodeType(str(ty), to_iter, from_iter)\n",
    "\n",
    "node_types: dict[type, NodeType] = {}\n",
    "register_pytree_node(tuple, lambda t: (None, t), lambda _, xs: tuple(xs))\n",
    "register_pytree_node(list,  lambda l: (None, l), lambda _, xs:  list(xs))\n",
    "register_pytree_node(dict,\n",
    "                     lambda d: map(tuple, unzip2(sorted(d.items()))),\n",
    "                     lambda keys, vals: dict(zip(keys, vals)))\n",
    "\n",
    "class PyTreeDef(NamedTuple):\n",
    "  node_type: NodeType\n",
    "  node_metadata: Hashable\n",
    "  child_treedefs: tuple['PyTreeDef', ...]\n",
    "\n",
    "class Leaf: pass\n",
    "leaf = Leaf()\n",
    "\n",
    "def tree_flatten(x: Any) -> tuple[list[Any], PyTreeDef]:\n",
    "  children_iter, treedef = _tree_flatten(x)\n",
    "  return list(children_iter), treedef\n",
    "\n",
    "def _tree_flatten(x: Any) -> tuple[Iterable, PyTreeDef]:\n",
    "  node_type = node_types.get(type(x))\n",
    "  if node_type:\n",
    "    node_metadata, children = node_type.to_iterable(x)\n",
    "    children_flat, child_trees = unzip2(map(_tree_flatten, children))\n",
    "    flattened = it.chain.from_iterable(children_flat)\n",
    "    return flattened, PyTreeDef(node_type, node_metadata, tuple(child_trees))\n",
    "  else:\n",
    "    return [x], leaf\n",
    "\n",
    "def tree_unflatten(treedef: PyTreeDef, xs: list[Any]) -> Any:\n",
    "  return _tree_unflatten(treedef, iter(xs))\n",
    "\n",
    "def _tree_unflatten(treedef: PyTreeDef, xs: Iterator) -> Any:\n",
    "  if treedef is leaf:\n",
    "    return next(xs)\n",
    "  else:\n",
    "    children = (_tree_unflatten(t, xs) for t in treedef.child_treedefs)\n",
    "    return treedef.node_type.from_iterable(treedef.node_metadata, children)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc44a5c-6cd6-4bd6-8d8b-77adc2f3b81d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mapped_aval(batch_dim, aval):\n",
    "  shape = list(aval.shape)\n",
    "  del shape[batch_dim]\n",
    "  return ShapedArray(tuple(shape), aval.dtype)\n",
    "\n",
    "def move_batch_axis(axis_size, src, dst, x):\n",
    "  if src is not_mapped:\n",
    "    target_shape = list(np.shape(x))\n",
    "    target_shape.insert(dst, axis_size)\n",
    "    return broadcast(x, target_shape, [dst])\n",
    "  elif src == dst:\n",
    "    return x\n",
    "  else:\n",
    "    return moveaxis(x, src, dst)\n",
    "\n",
    "def moveaxis(x, src: int, dst: int):\n",
    "  perm = [i for i in range(np.ndim(x)) if i != src]\n",
    "  perm.insert(dst, src)\n",
    "  return transpose(x, perm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3577e85-23c3-4ab2-8066-364fe5b6ec87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Union\n",
    "\n",
    "class NotMapped: pass\n",
    "not_mapped = NotMapped()\n",
    "\n",
    "BatchAxis = Union[NotMapped, int]\n",
    "\n",
    "class BatchTracer(Tracer):\n",
    "  def __init__(self, trace, val, batch_dim: BatchAxis):\n",
    "    self._trace = trace\n",
    "    self.val = val\n",
    "    self.batch_dim = batch_dim\n",
    "\n",
    "  @property\n",
    "  def aval(self):\n",
    "    if self.batch_dim is not_mapped:\n",
    "      return get_aval(self.val)\n",
    "    else:\n",
    "      return mapped_aval(self.batch_dim, get_aval(self.val))\n",
    "\n",
    "  def full_lower(self):\n",
    "    if self.batch_dim is not_mapped:\n",
    "      return full_lower(self.val)\n",
    "    else:\n",
    "      return self\n",
    "\n",
    "class BatchTrace(Trace):\n",
    "  pure = lift = lambda self, val: BatchTracer(self, val, not_mapped)\n",
    "\n",
    "  def process_primitive(self, primitive, tracers, params):\n",
    "    vals_in, bdims_in = unzip2((t.val, t.batch_dim) for t in tracers)\n",
    "    vmap_rule = vmap_rules[primitive]\n",
    "    val_outs, bdim_outs = vmap_rule(self.axis_size, vals_in, bdims_in, **params)\n",
    "    return [BatchTracer(self, x, bd) for x, bd in zip(val_outs, bdim_outs)]\n",
    "\n",
    "  @property\n",
    "  def axis_size(self):\n",
    "    return self.main.global_data\n",
    "\n",
    "vmap_rules = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69a53381-1395-48cd-a889-ff224ca9081a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "\n",
    "def binop_batching_rule(op, axis_size, vals_in, dims_in):\n",
    "  (x, y), (x_bdim, y_bdim) = vals_in, dims_in\n",
    "  if x_bdim != y_bdim:\n",
    "    if x_bdim is not_mapped:\n",
    "      x = move_batch_axis(axis_size, x_bdim, y_bdim, x)\n",
    "      x_bdim = y_bdim\n",
    "    else:\n",
    "      y = move_batch_axis(axis_size, y_bdim, x_bdim, y)\n",
    "  return [op(x, y)], [x_bdim]\n",
    "vmap_rules[add_p] = partial(binop_batching_rule, add)\n",
    "vmap_rules[mul_p] = partial(binop_batching_rule, mul)\n",
    "\n",
    "def vectorized_unop_batching_rule(op, axis_size, vals_in, dims_in):\n",
    "  (x,), (x_bdim,) = vals_in, dims_in\n",
    "  return [op(x)], [x_bdim]\n",
    "vmap_rules[sin_p] = partial(vectorized_unop_batching_rule, sin)\n",
    "vmap_rules[cos_p] = partial(vectorized_unop_batching_rule, cos)\n",
    "vmap_rules[neg_p] = partial(vectorized_unop_batching_rule, neg)\n",
    "\n",
    "def reduce_sum_batching_rule(axis_size, vals_in, dims_in, *, axis):\n",
    "  (x,), (x_bdim,) = vals_in, dims_in\n",
    "  new_axis = tuple(ax + (x_bdim <= ax) for ax in axis)\n",
    "  out_bdim = x_bdim - sum(ax < x_bdim for ax in axis)\n",
    "  return [reduce_sum(x, new_axis)], [out_bdim]\n",
    "vmap_rules[reduce_sum_p] = reduce_sum_batching_rule"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33a2b8b2-f069-4a06-b302-1143fc028164",
   "metadata": {},
   "outputs": [],
   "source": [
    "def vmap_flat(f, in_axes, *args):\n",
    "  axis_size, = {x.shape[ax] for x, ax in zip(args, in_axes)\n",
    "                if ax is not not_mapped}\n",
    "  with new_main(BatchTrace, axis_size) as main:\n",
    "    trace = BatchTrace(main)\n",
    "    tracers_in = [BatchTracer(trace, x, ax) if ax is not None else x\n",
    "                  for x, ax in zip(args, in_axes)]\n",
    "    outs = f(*tracers_in)\n",
    "    tracers_out = [full_raise(trace, out) for out in outs]\n",
    "    vals_out, bdims_out = unzip2((t.val, t.batch_dim) for t in tracers_out)\n",
    "  outs_transposed = [move_batch_axis(axis_size, bdim, 0, val_out)\n",
    "                     for val_out, bdim in zip(vals_out, bdims_out)]\n",
    "  return outs_transposed\n",
    "\n",
    "def vmap(f, in_axes):\n",
    "  def batched_f(*args):\n",
    "    args_flat, in_tree = tree_flatten(args)\n",
    "    in_axes_flat, in_tree2 = tree_flatten(in_axes)\n",
    "    if in_tree != in_tree2: raise TypeError\n",
    "    f_flat, out_tree = flatten_fun(f, in_tree)\n",
    "    outs_flat = vmap_flat(f_flat, in_axes_flat, *args_flat)\n",
    "    return tree_unflatten(out_tree(), outs_flat)\n",
    "  return batched_f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f179e2a7-378f-49f3-9a7d-4157faafeba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_one_to_a_scalar(scalar):\n",
    "  assert np.ndim(scalar) == 0\n",
    "  return 1 + scalar\n",
    "\n",
    "vector_in = np.arange(3.)\n",
    "vector_out = vmap(add_one_to_a_scalar, (0,))(vector_in)\n",
    "\n",
    "print(vector_in)\n",
    "print(vector_out)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f69889ce-a00f-4b39-af1f-3e5403b6e4c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def jacfwd(f, x):\n",
    "  pushfwd = lambda v: jvp(f, (x,), (v,))[1]\n",
    "  vecs_in = np.eye(np.size(x)).reshape(np.shape(x) * 2)\n",
    "  return vmap(pushfwd, (0,))(vecs_in)\n",
    "\n",
    "def f(x):\n",
    "  return sin(x)\n",
    "\n",
    "jacfwd(f, np.arange(3.))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "415d3aec-0451-4241-850a-de40ecf36354",
   "metadata": {},
   "source": [
    "# Part 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb44b5ac-4974-4b21-8ad2-d3b240d7d497",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Var:\n",
    "  aval: ShapedArray\n",
    "  def __init__(self, aval): self.aval = aval\n",
    "\n",
    "class Lit:\n",
    "  val: Any\n",
    "  aval: ShapedArray\n",
    "\n",
    "  def __init__(self, val):\n",
    "    self.aval = aval = raise_to_shaped(get_aval(val))\n",
    "    self.val = np.array(val, aval.dtype)\n",
    "\n",
    "Atom = Union[Var, Lit]\n",
    "\n",
    "class JaxprEqn(NamedTuple):\n",
    "  primitive: Primitive\n",
    "  inputs: list[Atom]\n",
    "  params: dict[str, Any]\n",
    "  out_binders: list[Var]\n",
    "\n",
    "class Jaxpr(NamedTuple):\n",
    "  in_binders: list[Var]\n",
    "  eqns: list[JaxprEqn]\n",
    "  outs: list[Atom]\n",
    "\n",
    "  def __hash__(self): return id(self)\n",
    "  __eq__ = op.is_\n",
    "\n",
    "def raise_to_shaped(aval):\n",
    "  return ShapedArray(aval.shape, aval.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "107b9f01-c3ba-4fef-8fd2-1e9917af518a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaxprType(NamedTuple):\n",
    "  in_types:  list[ShapedArray]\n",
    "  out_types: list[ShapedArray]\n",
    "\n",
    "  def __repr__(self):\n",
    "    in_types = ', '.join(aval.str_short() for aval in self.in_types)\n",
    "    out_types = ', '.join(aval.str_short() for aval in self.out_types)\n",
    "    return f'({in_types}) -> ({out_types})'\n",
    "\n",
    "def typecheck_jaxpr(jaxpr: Jaxpr) -> JaxprType:\n",
    "  env: set[Var] = set()\n",
    "\n",
    "  for v in jaxpr.in_binders:\n",
    "    if v in env: raise TypeError\n",
    "    env.add(v)\n",
    "\n",
    "  for eqn in jaxpr.eqns:\n",
    "    in_types = [typecheck_atom(env, x) for x in eqn.inputs]\n",
    "    out_types = abstract_eval_rules[eqn.primitive](*in_types, **eqn.params)\n",
    "    for out_binder, out_type in zip(eqn.out_binders, out_types):\n",
    "      if not out_type == out_binder.aval: raise TypeError\n",
    "    for out_binder in eqn.out_binders:\n",
    "      if out_binder in env: raise TypeError\n",
    "      env.add(out_binder)\n",
    "\n",
    "  in_types = [v.aval for v in jaxpr.in_binders]\n",
    "  out_types = [typecheck_atom(env, x) for x in jaxpr.outs]\n",
    "  return JaxprType(in_types, out_types)\n",
    "\n",
    "def typecheck_atom(env: set[Var], x: Atom) -> ShapedArray:\n",
    "  if isinstance(x, Var):\n",
    "    if x not in env: raise TypeError(\"unbound variable\")\n",
    "    return x.aval\n",
    "  elif isinstance(x, Lit):\n",
    "    return raise_to_shaped(get_aval(x.val))\n",
    "  else:\n",
    "    assert False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60c11b8b-413d-41fc-9f84-bc88bef36390",
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_jaxpr(jaxpr: Jaxpr, args: list[Any]) -> list[Any]:\n",
    "  env: dict[Var, Any] = {}\n",
    "\n",
    "  def read(x: Atom) -> Any:\n",
    "    return env[x] if type(x) is Var else x.val\n",
    "\n",
    "  def write(v: Var, val: Any) -> None:\n",
    "    assert v not in env  # single-assignment\n",
    "    env[v] = val\n",
    "\n",
    "  map(write, jaxpr.in_binders, args)\n",
    "  for eqn in jaxpr.eqns:\n",
    "    in_vals = map(read, eqn.inputs)\n",
    "    outs = bind(eqn.primitive, *in_vals, **eqn.params)\n",
    "    map(write, eqn.out_binders, outs)\n",
    "  return map(read, jaxpr.outs)\n",
    "\n",
    "def jaxpr_as_fun(jaxpr: Jaxpr):\n",
    "  return lambda *args: eval_jaxpr(jaxpr, args)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58851e1c-f634-4b16-975a-1c936900ac32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_list(lst: list[Any], n: int) -> tuple[list[Any], list[Any]]:\n",
    "  assert 0 <= n <= len(lst)\n",
    "  return lst[:n], lst[n:]\n",
    "\n",
    "def partition_list(bs: list[bool], l: list[Any]) -> tuple[list[Any], list[Any]]:\n",
    "  assert len(bs) == len(l)\n",
    "  lists = lst1, lst2 = [], []\n",
    "  for b, x in zip(bs, l):\n",
    "    lists[b].append(x)\n",
    "  return lst1, lst2\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c76ea9bc-6c4f-4613-b718-29b17d9ddab0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NB: the analogous class in JAX is called 'DynamicJaxprTracer'\n",
    "class JaxprTracer(Tracer):\n",
    "  __slots__ = ['aval']\n",
    "  aval: ShapedArray\n",
    "\n",
    "  def __init__(self, trace, aval):\n",
    "    self._trace = trace   # Points to `MainTrace` that has created this one.\n",
    "    self.aval = aval\n",
    "\n",
    "# NB: the analogous class in JAX is called 'DynamicJaxprTrace'\n",
    "class JaxprTrace(Trace):\n",
    "  def new_arg(self, aval: ShapedArray) -> JaxprTracer:\n",
    "    aval = raise_to_shaped(aval)\n",
    "    tracer = self.builder.new_tracer(self, aval)\n",
    "    self.builder.tracer_to_var[id(tracer)] = Var(aval)\n",
    "    return tracer\n",
    "\n",
    "  def get_or_make_const_tracer(self, val: Any) -> JaxprTracer:\n",
    "    tracer = self.builder.const_tracers.get(id(val))\n",
    "    if tracer is None:\n",
    "      tracer = self.builder.new_tracer(self, raise_to_shaped(get_aval(val)))\n",
    "      self.builder.add_const(tracer, val)\n",
    "    return tracer\n",
    "  pure = lift = get_or_make_const_tracer\n",
    "\n",
    "  def process_primitive(self, primitive, tracers, params):\n",
    "    avals_in = [t.aval for t in tracers]\n",
    "    avals_out = abstract_eval_rules[primitive](*avals_in, **params)\n",
    "    out_tracers = [self.builder.new_tracer(self, a) for a in avals_out]\n",
    "    inputs = [self.builder.getvar(t) for t in tracers]\n",
    "    outvars = [self.builder.add_var(t) for t in out_tracers]\n",
    "    self.builder.add_eqn(JaxprEqn(primitive, inputs, params, outvars))\n",
    "    return out_tracers\n",
    "\n",
    "  @property\n",
    "  def builder(self):\n",
    "    #raise ValueError(\"How the hell did I end here?\")\n",
    "    # Will be set by the `new_main()` context manager.\n",
    "    return self.main.global_data\n",
    "\n",
    "# NB: in JAX, we instead attach abstract eval rules to Primitive instances\n",
    "abstract_eval_rules = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a95afaf9-b905-4d8b-937f-2389be53d6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "class JaxprBuilder:\n",
    "  eqns: list[JaxprEqn]\n",
    "  tracer_to_var: dict[int, Var]\n",
    "  const_tracers: dict[int, JaxprTracer]\n",
    "  constvals: dict[Var, Any]\n",
    "  tracers: list[JaxprTracer]\n",
    "\n",
    "  def __init__(self):\n",
    "    self.eqns = []\n",
    "    self.tracer_to_var = {}\n",
    "    self.const_tracers = {}\n",
    "    self.constvals = {}\n",
    "    self.tracers = []\n",
    "\n",
    "  def new_tracer(self, trace: JaxprTrace, aval: ShapedArray) -> JaxprTracer:\n",
    "    tracer = JaxprTracer(trace, aval)\n",
    "    self.tracers.append(tracer)\n",
    "    return tracer\n",
    "\n",
    "  def add_eqn(self, eqn: JaxprEqn) -> None:\n",
    "    self.eqns.append(eqn)\n",
    "\n",
    "  def add_var(self, tracer: JaxprTracer) -> Var:\n",
    "    assert id(tracer) not in self.tracer_to_var\n",
    "    var = self.tracer_to_var[id(tracer)] = Var(tracer.aval)\n",
    "    return var\n",
    "\n",
    "  def getvar(self, tracer: JaxprTracer) -> Var:\n",
    "    var = self.tracer_to_var.get(id(tracer))\n",
    "    assert var is not None\n",
    "    return var\n",
    "\n",
    "  def add_const(self, tracer: JaxprTracer, val: Any) -> Var:\n",
    "    var = self.add_var(tracer)\n",
    "    self.const_tracers[id(val)] = tracer\n",
    "    self.constvals[var] = val\n",
    "    return var\n",
    "\n",
    "  def build(self, in_tracers: list[JaxprTracer], out_tracers: list[JaxprTracer]\n",
    "            ) -> tuple[Jaxpr, list[Any]]:\n",
    "    constvars, constvals = unzip2(self.constvals.items())\n",
    "    t2v = lambda t: self.tracer_to_var[id(t)]\n",
    "    in_binders = constvars + [t2v(t) for t in in_tracers]\n",
    "    out_vars = [t2v(t) for t in out_tracers]\n",
    "    jaxpr = Jaxpr(in_binders, self.eqns, out_vars)\n",
    "    typecheck_jaxpr(jaxpr)\n",
    "    jaxpr, constvals = _inline_literals(jaxpr, constvals)\n",
    "    return jaxpr, constvals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b75275a3-f0fa-45f4-9048-f0c1f8b56fd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _inline_literals(jaxpr: Jaxpr, consts: list[Any]) -> tuple[Jaxpr, list[Any]]:\n",
    "  const_binders, other_binders = split_list(jaxpr.in_binders, len(consts))\n",
    "  scalars = [type(x) in jax_types and not get_aval(x).shape for x in consts]\n",
    "  new_const_binders, lit_binders = partition_list(scalars, const_binders)\n",
    "  new_consts, lit_vals = partition_list(scalars, consts)\n",
    "  literals = dict(zip(lit_binders, map(Lit, lit_vals)))\n",
    "  new_eqns = [JaxprEqn(eqn.primitive, [literals.get(x, x) for x in eqn.inputs],\n",
    "                       eqn.params, eqn.out_binders) for eqn in jaxpr.eqns]\n",
    "  new_outs = [literals.get(x, x) for x in jaxpr.outs]\n",
    "  new_jaxpr = Jaxpr(new_const_binders + other_binders, new_eqns, new_outs)\n",
    "  typecheck_jaxpr(new_jaxpr)\n",
    "  return new_jaxpr, new_consts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf8f758-450b-477d-95b8-53364c6e1b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def binop_abstract_eval(x: ShapedArray, y: ShapedArray) -> list[ShapedArray]:\n",
    "  if not isinstance(x, ShapedArray) or not isinstance(y, ShapedArray):\n",
    "    raise TypeError\n",
    "  if raise_to_shaped(x) != raise_to_shaped(y): raise TypeError\n",
    "  return [ShapedArray(x.shape, x.dtype)]\n",
    "\n",
    "abstract_eval_rules[add_p] = binop_abstract_eval\n",
    "abstract_eval_rules[mul_p] = binop_abstract_eval\n",
    "\n",
    "def compare_abstract_eval(x: ShapedArray, y: ShapedArray) -> list[ShapedArray]:\n",
    "  if not isinstance(x, ShapedArray) or not isinstance(y, ShapedArray):\n",
    "    raise TypeError\n",
    "  if x.shape != y.shape: raise TypeError\n",
    "  return [ShapedArray(x.shape, np.dtype('bool'))]\n",
    "abstract_eval_rules[greater_p] = compare_abstract_eval\n",
    "abstract_eval_rules[less_p] = compare_abstract_eval\n",
    "\n",
    "def vectorized_unop_abstract_eval(x: ShapedArray) -> list[ShapedArray]:\n",
    "  return [ShapedArray(x.shape, x.dtype)]\n",
    "\n",
    "abstract_eval_rules[sin_p] = vectorized_unop_abstract_eval\n",
    "abstract_eval_rules[cos_p] = vectorized_unop_abstract_eval\n",
    "abstract_eval_rules[neg_p] = vectorized_unop_abstract_eval\n",
    "\n",
    "def reduce_sum_abstract_eval(x: ShapedArray, *, axis: tuple[int, ...]\n",
    "                             ) -> list[ShapedArray]:\n",
    "  axis_ = set(axis)\n",
    "  new_shape = [d for i, d in enumerate(x.shape) if i not in axis_]\n",
    "  return [ShapedArray(tuple(new_shape), x.dtype)]\n",
    "abstract_eval_rules[reduce_sum_p] = reduce_sum_abstract_eval\n",
    "\n",
    "def broadcast_abstract_eval(x: ShapedArray, *, shape: Sequence[int],\n",
    "                            axes: Sequence[int]) -> list[ShapedArray]:\n",
    "  return [ShapedArray(tuple(shape), x.dtype)]\n",
    "abstract_eval_rules[broadcast_p] = broadcast_abstract_eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6441a7ac-5c66-426b-8479-a0af305e5b7a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f67a7e91-a1d0-4913-acd8-63faff373b2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import lru_cache\n",
    "\n",
    "@lru_cache()  # ShapedArrays are hashable\n",
    "def make_jaxpr_v1(f, *avals_in):\n",
    "  avals_in, in_tree = tree_flatten(avals_in)\n",
    "  f, out_tree = flatten_fun(f, in_tree)\n",
    "\n",
    "  builder = JaxprBuilder()\n",
    "  with new_main(JaxprTrace, builder) as main:\n",
    "    trace = JaxprTrace(main)\n",
    "    tracers_in = [trace.new_arg(aval) for aval in avals_in]\n",
    "    outs = f(*tracers_in)\n",
    "    tracers_out = [full_raise(trace, out) for out in outs]\n",
    "    jaxpr, consts = builder.build(tracers_in, tracers_out)\n",
    "  return jaxpr, consts, out_tree()\n",
    "\n",
    "\n",
    "from collections import defaultdict\n",
    "import string\n",
    "\n",
    "class PPrint:\n",
    "  lines: list[tuple[int, str]]\n",
    "\n",
    "  def __init__(self, lines):\n",
    "    self.lines = lines\n",
    "\n",
    "  def indent(self, indent: int) -> 'PPrint':\n",
    "    return PPrint([(indent + orig_indent, s) for orig_indent, s in self.lines])\n",
    "\n",
    "  def __add__(self, rhs: 'PPrint') -> 'PPrint':\n",
    "    return PPrint(self.lines + rhs.lines)\n",
    "\n",
    "  def __rshift__(self, rhs: 'PPrint') -> 'PPrint':\n",
    "    if not rhs.lines: return self\n",
    "    if not self.lines: return rhs\n",
    "    indent, s = self.lines[-1]\n",
    "    indented_block = rhs.indent(indent + len(s))\n",
    "    common_line = s + ' ' * rhs.lines[0][0] + rhs.lines[0][1]\n",
    "    return PPrint(self.lines[:-1]\n",
    "                  + [(indent, common_line)]\n",
    "                  + indented_block.lines[1:])\n",
    "\n",
    "  def __str__(self) -> str:\n",
    "    return '\\n'.join(' ' * indent + s for indent, s in self.lines)\n",
    "\n",
    "def pp(s: Any) -> PPrint:\n",
    "  return PPrint([(0, line) for line in str(s).splitlines()])\n",
    "\n",
    "def vcat(ps: list[PPrint]) -> PPrint:\n",
    "  return sum(ps, pp(''))\n",
    "\n",
    "def pp_jaxpr(jaxpr: Jaxpr) -> PPrint:\n",
    "  namegen = (''.join(s) for r in it.count(1)\n",
    "             for s in it.permutations(string.ascii_lowercase, r))\n",
    "  names = defaultdict(lambda: next(namegen))\n",
    "  in_binders = ', '.join(var_str(names, x) for x in jaxpr.in_binders)\n",
    "  eqns = vcat([pp_eqn(names, e) for e in jaxpr.eqns])\n",
    "  outs = ', '.join(names[v] if isinstance(v, Var) else str(v.val)\n",
    "                   for v in jaxpr.outs)\n",
    "  return (pp(f'{{ lambda {in_binders} .') +\n",
    "          ((pp('let ') >> eqns) + pp(f'in ( {outs} ) }}')).indent(2))\n",
    "\n",
    "def var_str(names: defaultdict[Var, str], v: Var) -> str:\n",
    "  return f'{names[v]}:{v.aval.str_short()}'\n",
    "\n",
    "def pp_eqn(names: defaultdict[Var, str], eqn: JaxprEqn) -> PPrint:\n",
    "  rule = pp_rules.get(eqn.primitive)\n",
    "  if rule:\n",
    "    return rule(names, eqn)\n",
    "  else:\n",
    "    lhs = pp(' '.join(var_str(names, v) for v in eqn.out_binders))\n",
    "    rhs = (pp(eqn.primitive.name) >> pp_params(eqn.params) >>\n",
    "           pp(' '.join(names[x] if isinstance(x, Var) else str(x.val)\n",
    "                       for x in eqn.inputs)))\n",
    "    return lhs >> pp(' = ') >> rhs\n",
    "\n",
    "def pp_params(params: dict[str, Any]) -> PPrint:\n",
    "  items = sorted(params.items())\n",
    "  if items:\n",
    "    return pp(' [ ') >> vcat([pp(f'{k}={v}') for k, v in items]) >> pp(' ] ')\n",
    "  else:\n",
    "    return pp(' ')\n",
    "\n",
    "Jaxpr.__repr__ = lambda self: str(pp_jaxpr(self))\n",
    "pp_rules: dict[Primitive, Callable[..., PPrint]] = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "922551fa-0bde-40df-9919-70d8ff913bd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "jaxpr, consts, _ = make_jaxpr_v1(lambda x: 2. * x, raise_to_shaped(get_aval(3.)))\n",
    "print(jaxpr)\n",
    "print(typecheck_jaxpr(jaxpr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63010a7e-583f-456c-b33d-39fb26370ea6",
   "metadata": {},
   "outputs": [],
   "source": [
    "@contextmanager\n",
    "def new_dynamic(main: MainTrace):\n",
    "  global dynamic_trace\n",
    "  prev_dynamic_trace, dynamic_trace = dynamic_trace, main\n",
    "  try:\n",
    "    yield\n",
    "  finally:\n",
    "    dynamic_trace = prev_dynamic_trace\n",
    "\n",
    "@lru_cache()\n",
    "def make_jaxpr(f: Callable, *avals_in: ShapedArray,\n",
    "               ) -> tuple[Jaxpr, list[Any], PyTreeDef]:\n",
    "  avals_in, in_tree = tree_flatten(avals_in)\n",
    "  f, out_tree = flatten_fun(f, in_tree)\n",
    "\n",
    "  builder = JaxprBuilder()\n",
    "  with new_main(JaxprTrace, builder) as main:\n",
    "    with new_dynamic(main):\n",
    "      trace = JaxprTrace(main)\n",
    "      tracers_in = [trace.new_arg(aval) for aval in avals_in]\n",
    "      outs = f(*tracers_in)\n",
    "      tracers_out = [full_raise(trace, out) for out in outs]\n",
    "      jaxpr, consts = builder.build(tracers_in, tracers_out)\n",
    "  return jaxpr, consts, out_tree()\n",
    "\n",
    "jaxpr, consts, _ = make_jaxpr(lambda: mul(2., 2.))\n",
    "print(jaxpr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e927900a-65b8-44a2-897d-20b9c44d8b3a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a67eeb-25e0-4c50-949a-84a5231fc825",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f83d00a-cde2-45f5-a778-95fe7b3913f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e5e4757c-2f8f-4da1-baa4-9d840303582f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3419bb-b378-4807-86e5-f28615747a47",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d062f2-f67e-4b2f-9e05-5e04740af62a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b824887c-5a14-46c0-bd84-d9bc1f6418ee",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3685a51-901e-4e02-bee0-86e598e528ba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af34525d-a637-44de-a7e5-1796e8bed788",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77b08d71-5b1e-4197-9ab2-ba498f6824dc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7246a76-0900-4aae-b370-d208b4f4cced",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e18bb76d-4b33-4133-ad96-bde12f3867cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7a68fdb-83cb-418b-929e-f6359a01d1f6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8bee3e61-52da-4f6d-817e-98c41866eab2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a7e164c-bf27-409c-a753-ee64ea06477d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b08604c-b9f2-46b4-94a4-04f02a184d61",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b88021-482d-45cc-9715-63d7fd385912",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e579397b-45f3-4507-b23a-2258a870d575",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b865c24a-8159-40c4-807f-39cbb24ba783",
   "metadata": {},
   "outputs": [],
   "source": [
    "class A:\n",
    "    def __init__(self):\n",
    "        self.a = 1\n",
    "\n",
    "class B(A):\n",
    "    __slots__ = [\"b\"]\n",
    "\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.b = 0\n",
    "        self.c = 1\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1df2508e-4bb5-4de4-9310-b4f63f06e172",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = B()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cfab34f3-2b45-48c5-bc0e-3db58c23c278",
   "metadata": {},
   "outputs": [],
   "source": [
    "b.a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45f7c61b-f9cb-4ebb-bcfd-c1c00efcc721",
   "metadata": {},
   "outputs": [],
   "source": [
    "A.b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "368704a3-2f9f-4007-ac8a-dc54191fe976",
   "metadata": {},
   "outputs": [],
   "source": [
    "id(x.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39de3059-9748-42cd-b940-0547cce85c18",
   "metadata": {},
   "outputs": [],
   "source": [
    "id(z.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd4272-06b2-4779-99c9-64db98fc526a",
   "metadata": {},
   "outputs": [],
   "source": [
    "id(a.b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "760babea-5f58-44ac-9c2c-611606103355",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbc9580f-9ae0-4d89-acef-a6bbb2e53f76",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975abc75-c252-42ae-a8b3-9752936c3fdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15f5b4c5-fc59-48b5-9cb4-db453cd6a70d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d8c3908-1f1b-4a0f-b0f3-78607f2846fc",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
